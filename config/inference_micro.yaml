run_name: inference_micro_${summary_net.arch}
experiment: InferenceExperiment

dim: 6
summary_dim: 144
target_indices: [0,1,2,3,4,5]

num_test_points: 250
num_posterior_samples: 5000
sample_batch_size: 500

generative_model: INN
inn:
  num_blocks: 6
  layers_per_block: 2
  internal_size: 128
  spline_bound: 10
  num_bins: 10
  permute_soft: True
  latent_space: gaussian
  dropout: 0.

# summary_net:
#   out_channels: ${summary_dim}

use_extra_summary_mlp: False
extra_mlp:
  units:
    - ${summary_dim}
    - ${summary_dim}
    - ${summary_dim}
  act: relu
  out_act: null
  drop: 0.

use_attn_pool: False
attn_pool:
  embed_dim: ${summary_dim}
  out_channels: ${summary_dim}

data:
  dir: /scratch/ore/data/x5
  file_by_file: False

training:
  epochs: 500
  lr: 0.0001
  batch_size: 64
  test_batch_size: ${num_test_points}
  optimizer:
    name: AdamW
    kwargs: {}
  # scheduler:
  #   name: OneCycleLR
  #   kwargs: {max_lr: 1.e-3}

defaults:
  - default
  - preprocessing: xandy
  - net: mlp
  - net@summary_net: vit_micro
  - net@attn_pool: attn_head
  - _self_