run_name: inference_mini
experiment: InferenceExperiment

dim: 6
summary_dim: 128

num_test_points: 250
num_posterior_samples: 5000
sample_batch_size: 1000

generative_model: INN
inn:
  num_blocks: 6
  layers_per_block: 3
  internal_size: 256
  spline_bound: 10
  num_bins: 10
  permute_soft: True
  latent_space: gaussian
  dropout: 0.

summary_net:
  out_channels: ${summary_dim}

data:
  # not stored in gpu:
  # also use cluster.node=1 (no preferred gpu)
  dir: /remote/gpu01a/heneka/21cmlightcones/pure_simulations/x2
  # stored gpu01:
  #dir: /scratch2/heneka/21cmlightcones/pure_simulations/x2
  # stored gpu02:
  #dir: /scratch/ore/data/x2
  file_by_file: False

training:
  epochs: 100
  lr: 0.001
  batch_size: 32
  test_batch_size: ${num_test_points}
  optimizer:
    name: AdamW
    kwargs: {weight_decay: 0.001}

defaults:
  - default
  - preprocessing: xandy
  - net: mlp
  - net@summary_net: vit_mini
  - _self_