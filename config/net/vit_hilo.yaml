arch: HiLoViT

in_shape: [1, 140, 140, 470]
patch_shape: [1, 1, 1]  # redundant
out_channels: 6
hidden_dim: 144
depth: 4
num_heads: 4
mlp_ratio: 2.0
attn_drop: 0.
proj_drop: 0.
mlp_drop: 0.
out_act: sigmoid
checkpoint_grads: False
learn_pos_encoding: False  # redundant
use_patching: True # redundant
use_mask_token: False # redundant

use_head: False
head:
  _target_: src.networks.MLP
  cfg:
    units:
      - ${net.hidden_dim}
      - ${net.hidden_dim}
      - ${net.out_channels}
    act: relu
    out_act: ${net.out_act}
    drop: ${net.mlp_drop}

adapt_res: False  # redundant
use_input_conv: False  # redundant