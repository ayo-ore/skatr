arch: ViT
in_shape: [1, 70, 70, 1175]
out_channels: 6
# embedding size
patch_shape: [7, 7, 47]
condition_dim: 46
# multiple of 6, started at 240
hidden_dim: 360
# started at 4
depth: 8
num_heads: 8
mlp_ratio: 2.0
attn_drop: 0.
proj_drop: 0.
learn_pos_encoding: True
# final_conv: False
# final_conv_channels: None
long_skips: False
out_act: sigmoid

# experiment with: patch_shape, hidden_dim, depth, num_heads?, learn_pos_encoding? 