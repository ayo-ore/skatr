{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035c052e-34d1-4930-a74c-d3d67927f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/remote/gpu03/schiller/skatr\")\n",
    "# sys.path.append(\"..\")\n",
    "# sys.path.append(\"/home/hd/hd_hd/hd_ps236/skatr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a69289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddfff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.networks.llm_vit_construct.modeling_llm_vit import LLMViTForCausalLM\n",
    "from src.networks.llm_vit_construct.configuration_llm_vit import LLMViTConfig\n",
    "\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "model = LLMViTForCausalLM(LLMViTConfig(device_map=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd63153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from transformers.utils.__init__ import SAFE_WEIGHTS_INDEX_NAME\n",
    "from transformers.modeling_utils import load_state_dict, set_module_tensor_to_device\n",
    "from accelerate.utils.modeling import find_tied_parameters\n",
    "# from safetensors.torch import load_file\n",
    "import gc\n",
    "import fnmatch\n",
    "import torch\n",
    "\n",
    "# data_dir = \"/home/hd/hd_hd/hd_ps236/skatr/models/huggingface_models/Phi3_5_v\"\n",
    "data_dir = \"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\"\n",
    "\n",
    "archive_file = os.path.join(data_dir, SAFE_WEIGHTS_INDEX_NAME)\n",
    "modules_to_load = [\n",
    "    \"lm_head.weight\",\n",
    "    \"model.layers.*\",\n",
    "    \"model.norm.weight\"\n",
    "]\n",
    "\n",
    "def _to_be_loaded(name:str, modules_to_load:list[str]) -> False:\n",
    "    for module in modules_to_load:\n",
    "        if fnmatch.fnmatch(name, module):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "with open(archive_file, \"r\") as f:\n",
    "    index = json.loads(f.read())\n",
    "\n",
    "shard_filenames = sorted(set(index[\"weight_map\"].values()))\n",
    "sharded_metadata = index[\"metadata\"]\n",
    "sharded_metadata[\"all_checkpoint_keys\"] = list(index[\"weight_map\"].keys())\n",
    "sharded_metadata[\"weight_map\"] = index[\"weight_map\"].copy()\n",
    "shard_filenames = [os.path.join(data_dir, f) for f in shard_filenames]\n",
    "loaded_state_dict_keys = sharded_metadata[\"all_checkpoint_keys\"]\n",
    "\n",
    "model.tie_weights()\n",
    "model_state_dict = model.state_dict()\n",
    "_expected_keys = list(model_state_dict.keys())\n",
    "expected_keys = []\n",
    "for key in _expected_keys:\n",
    "    for module in modules_to_load:\n",
    "        if fnmatch.fnmatch(key, module):\n",
    "            expected_keys.append(key)\n",
    "            break\n",
    "\n",
    "loaded_keys = [key for key in loaded_state_dict_keys]\n",
    "prefix = model.base_model_prefix\n",
    "\n",
    "missing_keys = sorted(set(expected_keys) - set(loaded_keys))\n",
    "unexpected_keys = set(loaded_keys) - set(expected_keys)\n",
    "\n",
    "tied_params = find_tied_parameters(model)\n",
    "\n",
    "for group in tied_params:\n",
    "    missing_in_group = [k for k in missing_keys if k in group]\n",
    "    if len(missing_in_group) > 0 and len(missing_in_group) < len(group):\n",
    "        missing_keys = [k for k in missing_keys if k not in missing_in_group]\n",
    "\n",
    "not_initialized_submodules = dict(model.named_modules())\n",
    "dtype=torch.float32\n",
    "\n",
    "for shard_file in shard_filenames:\n",
    "    state_dict = load_state_dict(shard_file, False)\n",
    "\n",
    "    state_dict_to_load = {k: v for k,v in state_dict.items() if _to_be_loaded(k, modules_to_load)}\n",
    "    model.load_state_dict(state_dict_to_load, strict=False)\n",
    "\n",
    "    # for param_name, param in state_dict.items():\n",
    "\n",
    "    #     if param_name not in expected_keys:\n",
    "    #         continue\n",
    "\n",
    "    #     module_name = param_name\n",
    "    #     set_module_kwargs = {}\n",
    "        \n",
    "    #     param = param.to(dtype)\n",
    "\n",
    "    #     old_param = model\n",
    "    #     splits = param_name.split(\".\")\n",
    "    #     for split in splits:\n",
    "    #         old_param = getattr(old_param, split)\n",
    "    #         if old_param is None:\n",
    "    #             break\n",
    "    #     if old_param is not None:\n",
    "    #         if dtype is None:\n",
    "    #             param = param.to(old_param.dtype)\n",
    "\n",
    "    #         if old_param.is_contiguous():\n",
    "    #             param = param.contiguous()\n",
    "\n",
    "    #     set_module_kwargs[\"value\"] = param\n",
    "    #     set_module_kwargs[\"dtype\"] = torch.float32\n",
    "    #     set_module_tensor_to_device(model, param_name, \"cpu\", **set_module_kwargs)\n",
    "\n",
    "    del state_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e58d90-0314-4c29-9e6d-04c30e246975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "pages = convert_from_path('recovery.pdf')\n",
    "pages[0].save('image.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f39945-3c58-4de9-9567-46f34fcb0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(str(\"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\"))\n",
    "from skatr_vit_phi3_v import PretrainedViT\n",
    "\n",
    "vit_model = PretrainedViT(backbone_dir=\"/remote/gpu03/schiller/skatr/runs/regression_micro_ViT/2024-10-02_12-00-27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee889e37-e6b9-463b-a029-ff2f61d0f07f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hd/hd_hd/hd_ps236/.conda/envs/skatr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [10:53<00:00, 326.92s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "# quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "    # \"/remote/gpu03/schiller/ExecLLM/models/huggingface/microsoft/Phi-3.5-MoE-instruct\",\n",
    "    # \"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\",\n",
    "    \"/home/hd/hd_hd/hd_ps236/skatr/models/huggingface_models/Phi3_5_v\",\n",
    "    # device_map=\"cuda\",\n",
    "    device_map=\"cpu\", \n",
    "    torch_dtype=torch.bfloat16,  \n",
    "    trust_remote_code=True,\n",
    "    # quantization_config=quantization_config,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    _attn_implementation=\"eager\",\n",
    "    ignore_mismatched_sizes=True,\n",
    "    output_loading_info=True,\n",
    ")\n",
    "    \n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-MoE-instruct\", local_files_only=True) \n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"/remote/gpu03/schiller/ExecLLM/models/huggingface/microsoft/Phi-3.5-vision-instruct\", local_files_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c36936-f979-4a9a-a49e-d762004ab8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\")\n",
    "from skatr_vit_phi3_v import PretrainedViT, Phi3ImageEmbeddingSkatr\n",
    "\n",
    "model[0].config.img_processor = {\n",
    "    \"image_dim_out\": 144,\n",
    "    \"model_name\": \"\",\n",
    "    \"name\": \"vit\",\n",
    "    \"num_img_tokens\": 144,\n",
    "    \"backbone_dir\": \"/remote/gpu03/schiller/skatr/runs/regression_micro_ViT/2024-10-02_12-00-27\"\n",
    "    }\n",
    "embedding_config = {\n",
    "    'embedding_cls': model[0].config.embd_layer['embedding_cls'],\n",
    "    **model[0].config.embd_layer\n",
    "    }\n",
    "model[0].model.vision_embed_tokens = Phi3ImageEmbeddingSkatr(\n",
    "    model[0].config,\n",
    "    wte=model[0].model.embed_tokens,\n",
    "    **embedding_config\n",
    "    )\n",
    "# model[0].model.vision_embed_tokens.img_processor = PretrainedViT(backbone_dir=\"/remote/gpu03/schiller/skatr/runs/regression_micro_ViT/2024-10-02_12-00-27\")\n",
    "# model[0].config.embd_layer['use_hd_transform'] = False\n",
    "# model[0].config.embd_layer['with_learnable_separator'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3446cb-cf56-4052-9e22-bee6a463661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].save_pretrained(save_directory=\"/remote/gpu03/schiller/skatr/models/custom/Phi3_v_skatr\", safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c764998-7b2e-4cc5-800c-a26302b2b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\", \n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True,\n",
    "    patch_size = [4, 4, 10]\n",
    ")\n",
    "processor.save_pretrained(\"/remote/gpu03/schiller/skatr/models/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(str(\"/remote/gpu03/schiller/skatr/models\"))\n",
    "\n",
    "from convert_phi3_to_skatr import convert_phi3_to_skatr\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "\n",
    "load_dir = \"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\"\n",
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "    # \"/remote/gpu03/schiller/ExecLLM/models/huggingface/microsoft/Phi-3.5-MoE-instruct\",\n",
    "    \"/remote/gpu03/schiller/skatr/models/huggingface_models/Phi3_5_v\",\n",
    "    device_map=\"cuda\",  \n",
    "    torch_dtype=torch.bfloat16,  \n",
    "    trust_remote_code=True,\n",
    "    # quantization_config=quantization_config,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    ignore_mismatched_sizes=False,\n",
    "    output_loading_info=True,\n",
    ")\n",
    "\n",
    "model, processor = convert_phi3_to_skatr(model[0], patch_size=[4,4,10])\n",
    "\n",
    "print(f\"{processor.get_lightcone_param_token()} = {processor.lightcone_param_token_id()}\")\n",
    "\n",
    "save_dir=\"/remote/gpu03/schiller/skatr/models/custom/Phi3_v_skatr\"\n",
    "shutil.rmtree(save_dir)\n",
    "\n",
    "model.save_pretrained(save_directory=save_dir, safe_serialization=False)\n",
    "processor.save_pretrained(save_directory=save_dir)\n",
    "\n",
    "files_to_copy = [\"modeling_phi3_v.py\", \"skatr_vit_phi3_v.py\"]\n",
    "for file in files_to_copy:\n",
    "    shutil.copy(f\"{load_dir}/{file}\", f\"{save_dir}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.networks.llm_vit_construct.modeling_llm_vit import LLMViTForCausalLM\n",
    "from src.networks.llm_vit_construct.configuration_llm_vit import LLMViTConfig\n",
    "\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "\n",
    "model = LLMViTForCausalLM(LLMViTConfig(trust_remote_code=True, local_files_only=True,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "import shutil, os\n",
    "\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "\n",
    "# load_dir = \"/remote/gpu03/schiller/skatr/src/networks/llm_vit_construct\"\n",
    "# load_dir = \"../src/networks/llm_vit_construct\"\n",
    "load_dir = \"/home/hd/hd_hd/hd_ps236/skatr/src/networks/llm_vit_construct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(load_dir, trust_remote_code=True, local_files_only=True)\n",
    "model.load_vit_weights(\"vit_default.pt\")\n",
    "processor = AutoProcessor.from_pretrained(load_dir, trust_remote_code=True, local_files_only=True)\n",
    "\n",
    "# save_dir=\"/remote/gpu03/schiller/skatr/src/networks/llm_vit\"\n",
    "# save_dir=\"../src/networks/llm_vit\"\n",
    "save_dir = \"/home/hd/hd_hd/hd_ps236/skatr/src/networks/llm_vit\"\n",
    "if os.path.isdir(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "\n",
    "model.save_pretrained(save_directory=save_dir)\n",
    "processor.save_pretrained(save_directory=save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29391e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dir = '/remote/gpu02/ore/data/x5'\n",
    "index = 1000\n",
    "data_file = data_dir + f\"/run{index}.npz\"\n",
    "data = np.load(data_file)\n",
    "lightcone = data['image']\n",
    "\n",
    "images = [np.asarray(lightcone)]\n",
    "placeholder = f\"<|lightcone_1|>\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": placeholder+processor.get_lightcone_param_token()},\n",
    "]\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "output = model(**inputs, output_hidden_states=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455636a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mask = (inputs.input_ids[0,:] == processor.lightcone_param_token_id())\n",
    "param_positions = param_mask.nonzero(as_tuple=True)[0]\n",
    "param_pos = param_positions[0]\n",
    "\n",
    "print(output.hidden_states[:,param_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f3866-abbf-48de-9a06-4be6fff1a51c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "\n",
    "images = [Image.open(\"image.jpg\")]\n",
    "placeholder = f\"<|image_1|>\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": placeholder+\"Summarize this image.\"},\n",
    "]\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 1000, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(\n",
    "    **inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    ")\n",
    "\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(\n",
    "    generate_ids, \n",
    "    skip_special_tokens=True, \n",
    "    clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a245c3-bb19-4068-9d4f-3f55bd15f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dir = '/remote/gpu02/ore/data/x5'\n",
    "index = 1000\n",
    "data_file = data_dir + f\"/run{index}.npz\"\n",
    "data = np.load(data_file)\n",
    "print(data['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a78073-6db9-4183-8a9f-8e014afccfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_dict = {'image': data['image'].tolist(), 'label': data['label'].tolist()}\n",
    "# data_dict = {'image': data['image'][:10,:10,550:600].tolist(), 'label': data['label'].tolist()}\n",
    "data_str = json.dumps(data_dict)\n",
    "# print(data_str[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06b79c-fcd3-4750-86e4-9db13198691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": data_str},\n",
    "]\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "  messages, \n",
    "  tokenize=True,\n",
    "  add_generation_prompt=True\n",
    ")\n",
    "print(len(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f071151-a229-42c9-94c7-dc73537f7b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skatr",
   "language": "python",
   "name": "skatr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
