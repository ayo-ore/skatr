{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578f677f-d39c-4368-ae23-867899bf4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d5c729-8c77-4e31-8546-f3cf46d5d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_target_mask(num_patches, cfg, batch_size, device):\n",
    "    \"\"\"\n",
    "    cfg.num_targets: Number of targets to predict\n",
    "\n",
    "    Returns indices of target masks and context masks. Targets are either short range or long range \n",
    "    with different block sampling parameters respectively. The contexts are the complements of their targets.\n",
    "    \"\"\"\n",
    "    target_masks = []\n",
    "    context_masks = []\n",
    "    for i in range(cfg.num_targets):\n",
    "        print(i)\n",
    "        if i%2 == 0:\n",
    "            mode = 'short'\n",
    "            num_blocks = cfg.short_num_blocks\n",
    "        else:\n",
    "            mode = 'long'\n",
    "            num_blocks = cfg.long_num_blocks\n",
    "\n",
    "        target_mask, context_mask = block_mask(num_patches, cfg, batch_size, mode, device)\n",
    "        for i in range(num_blocks - 1):\n",
    "            target_mask_i, context_mask_i = block_mask(num_patches, cfg, batch_size, mode, device)\n",
    "            torch.cat((target_mask, target_mask_i), dim=0)\n",
    "            torch.cat((context_mask, context_mask_i), dim=0)\n",
    "        \n",
    "        target_masks.append(torch.unique(target_mask))\n",
    "        context_masks.append(torch.unique(context_mask))\n",
    "    return target_masks, context_mask\n",
    "\n",
    "def block_mask(num_patches, cfg, batch_size, mode, device):\n",
    "    \"\"\"\n",
    "    :param num_patches: iterable containing the number of patches per dimension\n",
    "\n",
    "    Returns indcs of mask and its complement\n",
    "    \"\"\"\n",
    "    height, width, depth = num_patches\n",
    "    h, w, d = block_size(num_patches, cfg, mode)\n",
    "\n",
    "    # Loop to sample masks until one large enough is found\n",
    "    min_keep = 4 # minimum number of patches to keep\n",
    "    tries = 0\n",
    "    timeout = 20\n",
    "    valid_mask = False\n",
    "    while not valid_mask:\n",
    "        # Sample block position\n",
    "        top = torch.randint(0, height - h + 1, (1,))\n",
    "        left = torch.randint(0, width - w + 1, (1,))\n",
    "        back = torch.randint(0, depth - d + 1, (1,))\n",
    "        mask = torch.zeros((height, width, depth), dtype=torch.int32)\n",
    "        mask[top:top+h, left:left+w, back:back+d] = 1\n",
    "        com_mask = 1 - mask\n",
    "        mask = mask.flatten()\n",
    "        com_mask = com_mask.flatten()\n",
    "\n",
    "        # If mask too small try again\n",
    "        valid_mask = len(mask) > min_keep\n",
    "        if not valid_mask:\n",
    "            timeout -= 1\n",
    "            if timeout == 0:\n",
    "                tries += 1\n",
    "                timeout = og_timeout\n",
    "    mask = mask.squeeze()\n",
    "    return mask, com_mask\n",
    "\n",
    "def block_size(num_patches, cfg, mode='context'):\n",
    "    \"\"\"\n",
    "    spatial_frac: range that spatial fraction is sampled from\n",
    "    redshift_frac: range that redshift fraction is sampled from\n",
    "    aspect_scale: range that x and y ratio is sampled from\n",
    "    mode: whether to use short or long range sampling parameters\n",
    "\n",
    "    Helper to sample block mask dimensions\n",
    "    \"\"\"\n",
    "    max_dims = num_patches\n",
    "    spacial_aspect_range = cfg.spacial_aspect\n",
    "    if mode=='short':\n",
    "        spatial_frac_range = cfg.short_spatial_frac\n",
    "        redshift_frac_range = cfg.short_redshift_frac\n",
    "    else:\n",
    "        spatial_frac_range = cfg.long_spatial_frac\n",
    "        redshift_frac_range = cfg.long_redshift_frac\n",
    "\n",
    "    spatial_frac = sample_ratio(*spacial_aspect_range) if type(spacial_aspect_range) != int else spacial_aspect_range\n",
    "    redshift_frac = sample_ratio(*redshift_frac_range) if type(redshift_frac_range) != int else redshift_frac_range\n",
    "    while True:\n",
    "        # Sample ratios such that all dimensions are restricted to within a unit cube\n",
    "        spatial_aspect = sample_aspect_ratio(*spacial_aspect_range)\n",
    "\n",
    "        h = math.sqrt(spatial_frac * spatial_aspect)\n",
    "        w = math.sqrt(spatial_frac / spatial_aspect)\n",
    "        d = redshift_frac\n",
    "        dims = [h, w, d]\n",
    "        dim_outside = [dim > 1. for dim in dims]\n",
    "        if not any(dim_outside): break\n",
    "\n",
    "    # Scale unit cube dimensions to number of patches\n",
    "    for i, dim in enumerate(dims):\n",
    "        dims[i] = round(dim * max_dims[i])\n",
    "    \n",
    "    return dims\n",
    "\n",
    "def sample_aspect_ratio(min, max):\n",
    "    # Sample a single aspect-ratio, ensuring that both dimensions are equally \n",
    "    # likely to be scaled up or down\n",
    "    if torch.randint(0, 2, (1,)) == 0:\n",
    "        max = 1.\n",
    "    else:\n",
    "        min = 1.\n",
    "    return (min - max) * torch.rand(1,) + max\n",
    "\n",
    "def sample_ratio(min, max):\n",
    "    return (min - max) * torch.rand(1,) + max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8d2157-f940-469f-bbcd-7b70b3ba71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shape = [2,2,4]\n",
    "batch_size = 2\n",
    "axis_sizes = [8, 8, 16]\n",
    "device = 'cuda'\n",
    "num_patches = [s // p for s, p in zip(axis_sizes, patch_shape)]\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.num_targets = 4\n",
    "        self.spacial_aspect = [0.75, 1.5]\n",
    "        self.short_num_blocks = 8\n",
    "        self.short_spatial_frac = [0.1, 0.2]\n",
    "        self.short_redshift_frac = 1\n",
    "        self.long_num_blocks = 2\n",
    "        self.long_spatial_frac = [0.6, 0.8]\n",
    "        self.long_redshift_frac = 1\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a89b3-910c-4403-ae62-954014c626f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "context_target_mask(num_patches, cfg, batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba23b56-0276-4a22-81d3-6273ea9735fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/scratch2/heneka/21cmlightcones/pure_simulations'\n",
    "DATA_DIR = '/remote/gpu01a/heneka/21cmlightcones/pure_simulations'\n",
    "\n",
    "files = glob(f'{DATA_DIR}/*.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc57ef2-f634-498e-8d70-9f518f2f6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = [140, 140, 2350]\n",
    "RESHAPE_2 = [r for s in SHAPE for r in [s//2, 2]]\n",
    "RESHAPE_5 = [r for s in SHAPE for r in [s//5, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75e39c-9046-4ac4-b42b-986e6e7ddbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(files[0])['image']\n",
    "rand_int = int(np.random.rand()*3)\n",
    "x1 = np.rot90(x, np.random.rand(), axes=(1,0))\n",
    "x2 = np.rot90(x, 2, axes=(1,0))\n",
    "x3 = np.rot90(x, 3, axes=(1,0))\n",
    "x4 = np.rot90(x, 4, axes=(1,0))\n",
    "\n",
    "y2 = np.mean(x.reshape(*RESHAPE_2), axis=(1, 3, 5))\n",
    "y5 = np.mean(x.reshape(*RESHAPE_5), axis=(1, 3, 5))  \n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d5928-3910-4759-ac15-8f4e7adc363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "patch_shape = [4, 4, 5]\n",
    "in_channels, *axis_sizes = [1, 28, 28, 470]\n",
    "num_patches = [s // p for s, p in zip(axis_sizes, patch_shape)]\n",
    "\n",
    "def to_patches(x):\n",
    "    x = rearrange(\n",
    "        x, '(x p1) (y p2) (z p3) -> x y z) (p1 p2 p3)',\n",
    "        **dict(zip(('p1', 'p2', 'p3'), patch_shape))\n",
    "    )\n",
    "    return x\n",
    "\n",
    "def from_patches(x):\n",
    "    x = rearrange(\n",
    "        x, '(x y z) (p1 p2 p3) -> (x p1) (y p2) (z p3)',\n",
    "        **dict(zip(('x', 'y', 'z', 'p1', 'p2', 'p3'), num_patches+patch_shape))\n",
    "    )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b5149-799e-46a7-8257-6d5412cd8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mask_frac_scale = [0.2, 0.2]\n",
    "mask_aspect_scale = [0.75, 1.5]\n",
    "\n",
    "patch_shape = [4, 4, 5]\n",
    "in_channels, *axis_sizes = [1, 28, 28, 470]\n",
    "num_patches = [s // p for s, p in zip(axis_sizes, patch_shape)]\n",
    "\n",
    "def sample_block_size():\n",
    "    \"\"\"\n",
    "    Helper that samples block mask dimensions\n",
    "    cfg.mask_frac_scale: interval that a block fraction is sampled from\n",
    "    cfg.mask_aspect_scale: interval that x and y ratio is sampled from\n",
    "    \"\"\"\n",
    "    max_dims = num_patches\n",
    "\n",
    "    # Sample cube volume ie. mask fraction\n",
    "    min_s, max_s = mask_frac_scale\n",
    "    v = random.uniform(min_s, max_s)\n",
    "\n",
    "    # Sample two aspect-ratios, between z & x and z & y respectively\n",
    "    def sample_aspect_ratio():\n",
    "        # Sample a single aspect-ratio, ensuring that both dimensions are equally likely to be scaled up or down\n",
    "        min_ar, max_ar = mask_aspect_scale\n",
    "        if torch.randint(0, 2, (1,)) == 0:\n",
    "            max_ar = 1.\n",
    "        else:\n",
    "            min_ar = 1.\n",
    "        aspect_ratio = (min_ar - max_ar) * torch.rand(1,) + max_ar\n",
    "        return aspect_ratio\n",
    "\n",
    "    while True:\n",
    "        # Sample ratios such that all dimensions are restricted to within a unit cube\n",
    "        ratio_h = sample_aspect_ratio()\n",
    "        ratio_w = sample_aspect_ratio()\n",
    "        d = math.cbrt(v / (ratio_h * ratio_w))\n",
    "        h = ratio_h * d\n",
    "        w = ratio_w * d\n",
    "        dims = [h, w, d]\n",
    "        dim_outside = [dim > 1. for dim in dims]\n",
    "        if not any(dim_outside): break\n",
    "\n",
    "    # Scale unit cube dimensions to number of patches\n",
    "    for j in range(len(dims)):\n",
    "        dims[j] = int(dims[j] * max_dims[j] + .5)\n",
    "    \n",
    "    return dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d28e8d-8d5e-41ff-b136-c6bcc901bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_block_mask():\n",
    "    \"\"\"\n",
    "    Helper that samples boolean block mask\n",
    "    TODO: ensure that blocks shapes are sampled \n",
    "    \"\"\"\n",
    "    height, width, depth = num_patches\n",
    "    h, w, d = sample_block_size()\n",
    "\n",
    "    # Loop to sample masks until we find a valid one\n",
    "    tries = 0\n",
    "    timeout = 20\n",
    "    valid_mask = False\n",
    "    while not valid_mask:\n",
    "        # Sample block top-left corner\n",
    "        top = torch.randint(0, height - h + 1, (1,))\n",
    "        left = torch.randint(0, width - w + 1, (1,))\n",
    "        back = torch.randint(0, depth - d + 1, (1,))\n",
    "        mask_map = torch.zeros((height, width, depth), dtype=torch.int32)\n",
    "        mask_map[top:top+h, left:left+w, back:back+d] = 1\n",
    "        #mask_map = mask_map.flatten()\n",
    "        # If mask too small try again\n",
    "        min_keep = 4 # minimum number of patches to keep\n",
    "        valid_mask = len(mask_map) > min_keep\n",
    "        if not valid_mask:\n",
    "            timeout -= 1\n",
    "            if timeout == 0:\n",
    "                tries += 1\n",
    "                timeout = og_timeout\n",
    "    mask_map = mask_map.squeeze().bool()\n",
    "    return mask_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54514c5b-5585-4ffe-b058-c50a2c527e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(num_patches)\n",
    "for i in range(20):\n",
    "    print(sample_block_mask())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb989f2-001a-4328-bf83-103e23eaa44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "sizes = np.array([0,0,0])\n",
    "for i in range (iterations):\n",
    "    sizes += sample_block_size()\n",
    "mean_blocks = np.array(sizes)/iterations/num_patches\n",
    "print(mean_blocks)\n",
    "print(math.prod(mean_blocks)/np.mean(mask_frac_scale))\n",
    "#print(sample_block_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39706725-7b91-4d4d-848d-10e7027c9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixes asymmetrical sampling\n",
    "mask_aspect_scale = [0.3, 3]\n",
    "ratios = []\n",
    "for i in range (100000):\n",
    "    min_ar, max_ar = mask_aspect_scale\n",
    "    if torch.rand(1,) < .5:\n",
    "        max_ar = 1\n",
    "    else:\n",
    "        min_ar = 1\n",
    "    aspect_ratio = (min_ar - max_ar) * torch.rand(1,) + max_ar\n",
    "    ratios.append(aspect_ratio > 1)\n",
    "np.mean(np.array(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e525643-db14-4821-8171-87dd9008da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version\n",
    "mask_aspect_scale = [0.3, 3.0]\n",
    "min_ar, max_ar = mask_aspect_scale\n",
    "ratios = []\n",
    "for i in range (1000):\n",
    "    aspect_ratio = (min_ar - max_ar) * torch.rand(1,) + max_ar\n",
    "    ratios.append(aspect_ratio > 1)\n",
    "np.mean(np.array(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ac2f0-6699-42e3-919e-3ebd1c0fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_boolean_tensor_3d(tensor):\n",
    "    if not tensor.dtype == torch.bool:\n",
    "        raise ValueError(\"The input tensor must be a boolean tensor\")\n",
    "    if len(tensor.shape) != 3:\n",
    "        raise ValueError(\"The input tensor must have 3 dimensions\")\n",
    "    \n",
    "    num_slices = tensor.shape[2]\n",
    "    \n",
    "    # Determine grid size for plotting\n",
    "    ncols = int(np.ceil(np.sqrt(num_slices)))\n",
    "    nrows = int(np.ceil(num_slices / ncols))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        ax = axes[i]\n",
    "        slice_2d = tensor[:, :, i].numpy()\n",
    "        cax = ax.matshow(slice_2d, cmap='Greys')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f'Slice {i+1}')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_slices, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658845e-955f-4da7-9d3b-8f29fbea9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boolean_tensor_3d(tensor):\n",
    "    if not tensor.dtype == torch.bool:\n",
    "        raise ValueError(\"The input tensor must be a boolean tensor\")\n",
    "    if len(tensor.shape) != 3:\n",
    "        raise ValueError(\"The input tensor must have 3 dimensions\")\n",
    "    \n",
    "    num_slices = tensor.shape[2]\n",
    "    \n",
    "    # Determine grid size for plotting\n",
    "    ncols = int(np.ceil(np.sqrt(num_slices)))\n",
    "    nrows = int(np.ceil(num_slices / ncols))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        ax = axes[i]\n",
    "        slice_2d = tensor[:, :, i].numpy()\n",
    "        cax = ax.matshow(slice_2d, cmap='Greys')\n",
    "        \n",
    "        # Setting x and y ticks\n",
    "        ax.set_xticks(np.arange(slice_2d.shape[1]))\n",
    "        ax.set_yticks(np.arange(slice_2d.shape[0]))\n",
    "        \n",
    "        # Optional: To label the ticks with their indices\n",
    "        ax.set_xticklabels(np.arange(slice_2d.shape[1]))\n",
    "        ax.set_yticklabels(np.arange(slice_2d.shape[0]))\n",
    "        \n",
    "        ax.set_title(f'Slice {i+1}')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_slices, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6126f5-dc93-4ba9-a2e8-59d2bd8fe6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sample_block_mask()\n",
    "visualize_boolean_tensor_3d(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96348f22-626e-4699-a69b-1980c108ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boolean_tensor(tensor):\n",
    "    if not tensor.dtype == torch.bool:\n",
    "        raise ValueError(\"The input tensor must be a boolean tensor\")\n",
    "    \n",
    "    # Convert the tensor to a numpy array\n",
    "    tensor_np = tensor.numpy()\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Create a heatmap using the numpy array\n",
    "    cax = ax.matshow(tensor_np, cmap='Greys')\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_xticks(np.arange(tensor_np.shape[1]))\n",
    "    ax.set_yticks(np.arange(tensor_np.shape[0]))\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cef864-f972-4687-b19c-923ee763f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8009f4-0b3d-4e7f-8d70-7d5a2c12da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boolean_tensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779fc8c-f889-4cf9-9c4f-80a1fe243b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sample_block_mask(x)\n",
    "to_patches(x).shape\n",
    "#from_patches(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb59fc-32e2-4920-8081-50e77c858ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rotations(idx):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(12, 4))\n",
    "    \n",
    "    ax[0].imshow(x[:, :, idx])\n",
    "    ax[1].imshow(x1[:, :, idx])\n",
    "    ax[2].imshow(x2[:, :, idx])\n",
    "    ax[3].imshow(x3[:, :, idx])\n",
    "    ax[4].imshow(x4[:, :, idx])\n",
    "\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].set_title('90')\n",
    "    ax[2].set_title('180')\n",
    "    ax[3].set_title('270')\n",
    "    ax[4].set_title('360')\n",
    "    ax[4].set_title(rand_int*90)\n",
    "compare_rotations(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2936334-1fad-4abc-afd1-ddeaeaad488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_resolutions(idx):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 4))\n",
    "    \n",
    "    ax[0].imshow(x[:, :, idx])\n",
    "    ax[1].imshow(y2[:, :, idx//2])\n",
    "    ax[2].imshow(y5[:, :, idx//5])\n",
    "    ax[3].imshow(x1[:, :, idx])\n",
    "\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].set_title('x2')\n",
    "    ax[2].set_title('x5')\n",
    "    ax[3].set_title('Rotated')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286288a-f4f7-441b-b1a6-c3bcd52ffc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_resolutions(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcd352-8e71-4ab6-830c-52984898f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_resolutions(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57d46d-942d-4011-88c0-fa595a5f01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_resolutions(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8616fe-002b-4b98-a87c-17049e7aea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_resolutions(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skatr",
   "language": "python",
   "name": "skatr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
